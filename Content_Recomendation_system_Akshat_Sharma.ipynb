{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR2LVjzAYzWN",
        "outputId": "d93f247c-af4d-47b9-f331-a0f94f5b136e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Packages installed. Proceed to next cell to upload kaggle.json (for books/anime/songs).\n"
          ]
        }
      ],
      "source": [
        "# Cell 0 â€” Install required packages\n",
        "!pip install -q --upgrade numpy==1.26.4\n",
        "!pip install -q --upgrade pandas\n",
        "!pip install -q --upgrade scipy\n",
        "!pip install -q --upgrade scikit-learn\n",
        "!pip install -q kaggle gradio==3.40.1\n",
        "\n",
        "print(\"âœ… Packages installed. Proceed to next cell to upload kaggle.json (for books/anime/songs).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "8nEknl_yY1nb",
        "outputId": "0a741990-c2df-4335-f6b0-a7c716518679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“‚ Please upload your kaggle.json now.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c169464a-a023-4e0f-a0ca-cf47e2bc0c3a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c169464a-a023-4e0f-a0ca-cf47e2bc0c3a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "â¬‡ï¸ Downloading Kaggle datasets...\n",
            "Dataset URL: https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset\n",
            "License(s): CC0-1.0\n",
            "Dataset URL: https://www.kaggle.com/datasets/cooperunion/anime-recommendations-database\n",
            "License(s): CC0-1.0\n",
            "Dataset URL: https://www.kaggle.com/datasets/notshrirang/spotify-million-song-dataset\n",
            "License(s): CC0-1.0\n",
            "\n",
            "â¬‡ï¸ Downloading MovieLens dataset from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip...\n",
            "âœ… MovieLens dataset downloaded and extracted.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1 â€” Upload kaggle.json and download datasets\n",
        "from google.colab import files\n",
        "import os, sys, time\n",
        "import requests, zipfile, io\n",
        "\n",
        "print(\"ðŸ“‚ Please upload your kaggle.json now.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "for filename in uploaded.keys():\n",
        "    if 'kaggle' in filename:\n",
        "        open('/root/.kaggle/kaggle.json','wb').write(uploaded[filename])\n",
        "        os.chmod('/root/.kaggle/kaggle.json', 0o600)\n",
        "\n",
        "# Create data folders\n",
        "os.makedirs(\"data/movies\", exist_ok=True)\n",
        "os.makedirs(\"data/books\", exist_ok=True)\n",
        "os.makedirs(\"data/anime\", exist_ok=True)\n",
        "os.makedirs(\"data/songs\", exist_ok=True)\n",
        "\n",
        "# Download Kaggle datasets\n",
        "print(\"â¬‡ï¸ Downloading Kaggle datasets...\")\n",
        "!kaggle datasets download -d arashnic/book-recommendation-dataset -p data/books --unzip -q || true\n",
        "!kaggle datasets download -d cooperunion/anime-recommendations-database -p data/anime --unzip -q || true\n",
        "!kaggle datasets download -d notshrirang/spotify-million-song-dataset -p data/songs --unzip -q || true\n",
        "\n",
        "# MovieLens dataset direct download\n",
        "movielens_url = \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        "movielens_dir = \"data/movies/ml-latest-small\"\n",
        "print(f\"\\nâ¬‡ï¸ Downloading MovieLens dataset from {movielens_url}...\")\n",
        "try:\n",
        "    r = requests.get(movielens_url, stream=True)\n",
        "    r.raise_for_status()\n",
        "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "    z.extractall(\"data/movies/\")\n",
        "    print(\"âœ… MovieLens dataset downloaded and extracted.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ MovieLens download failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKsV5gO0Y4If",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed7b527-79ca-4961-f09e-c480d61a083a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded data/movies/ml-latest-small/ratings.csv: (100836, 4)\n",
            "âœ… Loaded data/movies/ml-latest-small/movies.csv: (9742, 3)\n",
            "âœ… Loaded data/books/Books.csv: (271360, 8)\n",
            "âœ… Loaded data/books/Ratings.csv: (1149780, 3)\n",
            "âœ… Loaded data/anime/anime.csv: (12294, 7)\n",
            "âœ… Loaded data/anime/rating.csv: (7813737, 3)\n",
            "âœ… Loaded data/songs/spotify_millsongdata.csv: (57650, 4)\n"
          ]
        }
      ],
      "source": [
        "# Cell 2 â€” Load datasets\n",
        "import pandas as pd, os\n",
        "\n",
        "def safe_load_csv(path, nrows=None):\n",
        "    try:\n",
        "        df = pd.read_csv(path, nrows=nrows, low_memory=False)\n",
        "        print(f\"âœ… Loaded {path}: {df.shape}\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Could not load {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# MovieLens (guaranteed now)\n",
        "movies_ratings = safe_load_csv(\"data/movies/ml-latest-small/ratings.csv\")\n",
        "movies_items   = safe_load_csv(\"data/movies/ml-latest-small/movies.csv\")\n",
        "\n",
        "# Books\n",
        "books_items   = safe_load_csv(\"data/books/Books.csv\")\n",
        "books_ratings = safe_load_csv(\"data/books/Ratings.csv\")\n",
        "\n",
        "# Anime\n",
        "anime_items   = safe_load_csv(\"data/anime/anime.csv\")\n",
        "anime_ratings = safe_load_csv(\"data/anime/rating.csv\")\n",
        "\n",
        "# Songs\n",
        "songs_raw = safe_load_csv(\"data/songs/spotify_millsongdata.csv\", nrows=100000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auuW-ZE5H-t3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc8b4be-135a-425f-f1a6-0d6e7be1172c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standardization done. Quick shapes:\n",
            "movies_items: (9742, 3)\n",
            "movies_ratings: (100836, 3)\n",
            "books_items: (271360, 8)\n",
            "books_ratings: (1149780, 3)\n",
            "anime_items: (12294, 7)\n",
            "anime_ratings: (7813737, 3)\n",
            "songs_items: (57650, 5)\n",
            "songs_ratings: (57650, 3)\n"
          ]
        }
      ],
      "source": [
        "# Cell 3 â€” Normalize column names into consistent schema\n",
        "def ensure_cols_items(df, item_col_candidates, title_candidates, genre_candidates):\n",
        "    if df is None:\n",
        "        return None\n",
        "    df = df.copy()\n",
        "    # item id\n",
        "    for c in item_col_candidates:\n",
        "        if c in df.columns:\n",
        "            df = df.rename(columns={c: \"itemId\"})\n",
        "            break\n",
        "    if \"itemId\" not in df.columns:\n",
        "        df[\"itemId\"] = range(1, len(df)+1)\n",
        "    # title\n",
        "    for c in title_candidates:\n",
        "        if c in df.columns:\n",
        "            df = df.rename(columns={c: \"title\"})\n",
        "            break\n",
        "    if \"title\" not in df.columns:\n",
        "        df[\"title\"] = df[\"itemId\"].astype(str)\n",
        "    # genres\n",
        "    for c in genre_candidates:\n",
        "        if c in df.columns:\n",
        "            df = df.rename(columns={c: \"genres\"})\n",
        "            break\n",
        "    if \"genres\" not in df.columns:\n",
        "        df[\"genres\"] = \"\"\n",
        "    return df\n",
        "\n",
        "def ensure_cols_ratings(df, user_candidates, item_candidates, rating_candidates):\n",
        "    if df is None:\n",
        "        return None\n",
        "    df = df.copy()\n",
        "    for c in user_candidates:\n",
        "        if c in df.columns:\n",
        "            df = df.rename(columns={c: \"userId\"})\n",
        "            break\n",
        "    if \"userId\" not in df.columns:\n",
        "        # If no user ID column found, create a placeholder column (all users are 'default_user')\n",
        "        df[\"userId\"] = \"default_user\"\n",
        "\n",
        "    for c in item_candidates:\n",
        "        if c in df.columns:\n",
        "            df = df.rename(columns={c: \"itemId\"})\n",
        "            break\n",
        "    # Ensure itemId is created even if not found in candidates\n",
        "    if \"itemId\" not in df.columns and \"title\" in df.columns:\n",
        "        df[\"itemId\"] = df[\"title\"]\n",
        "    elif \"itemId\" not in df.columns:\n",
        "        # Fallback to using row index if no itemId or title found\n",
        "         df[\"itemId\"] = range(1, len(df) + 1)\n",
        "\n",
        "\n",
        "    for c in rating_candidates:\n",
        "        if c in df.columns:\n",
        "            df = df.rename(columns={c: \"rating\"})\n",
        "            break\n",
        "    if \"rating\" not in df.columns:\n",
        "        # Default rating if no rating column found\n",
        "        df[\"rating\"] = 1\n",
        "    # keep only these columns\n",
        "    return df[[\"userId\", \"itemId\", \"rating\"]]\n",
        "\n",
        "# Apply for movies\n",
        "movies_items = ensure_cols_items(movies_items,\n",
        "    item_col_candidates=[\"id\",\"movieId\",\"itemId\"],\n",
        "    title_candidates=[\"title\",\"name\"],\n",
        "    genre_candidates=[\"genres\",\"genre\"]\n",
        ") if movies_items is not None else None\n",
        "\n",
        "movies_ratings = ensure_cols_ratings(movies_ratings,\n",
        "    user_candidates=[\"userId\",\"user_id\",\"User-ID\"],\n",
        "    item_candidates=[\"movieId\",\"itemId\",\"id\"],\n",
        "    rating_candidates=[\"rating\"]\n",
        ")\n",
        "\n",
        "# Books\n",
        "books_items = ensure_cols_items(books_items,\n",
        "    item_col_candidates=[\"ISBN\",\"book_id\",\"itemId\"],\n",
        "    title_candidates=[\"Book-Title\",\"title\"],\n",
        "    genre_candidates=[\"Book-Author\",\"authors\",\"genres\"]\n",
        ") if books_items is not None else None\n",
        "\n",
        "books_ratings = ensure_cols_ratings(books_ratings,\n",
        "    user_candidates=[\"User-ID\",\"userId\",\"user_id\"],\n",
        "    item_candidates=[\"ISBN\",\"book_id\",\"itemId\"],\n",
        "    rating_candidates=[\"Book-Rating\",\"rating\"]\n",
        ")\n",
        "\n",
        "# Anime\n",
        "anime_items = ensure_cols_items(anime_items,\n",
        "    item_col_candidates=[\"anime_id\",\"itemId\",\"id\"],\n",
        "    title_candidates=[\"name\",\"title\"],\n",
        "    genre_candidates=[\"genre\",\"genres\"]\n",
        ") if anime_items is not None else None\n",
        "\n",
        "anime_ratings = ensure_cols_ratings(anime_ratings,\n",
        "    user_candidates=[\"user_id\",\"userId\"],\n",
        "    item_candidates=[\"anime_id\",\"itemId\"],\n",
        "    rating_candidates=[\"rating\"]\n",
        ")\n",
        "\n",
        "# Songs\n",
        "songs_items = ensure_cols_items(songs_raw,\n",
        "    item_col_candidates=[\"track_id\",\"id\",\"itemId\"],\n",
        "    title_candidates=[\"song\",\"track_name\",\"title\",\"name\"], # Added 'song'\n",
        "    genre_candidates=[\"artist\",\"genres\"] # Added 'artist'\n",
        ") if songs_raw is not None else None\n",
        "\n",
        "songs_ratings = ensure_cols_ratings(songs_raw,\n",
        "    user_candidates=[\"userId\",\"user_id\"],\n",
        "    item_candidates=[\"track_id\",\"itemId\"],\n",
        "    rating_candidates=[\"popularity\",\"rating\"] # There's no rating in song data, default will be used\n",
        ")\n",
        "\n",
        "print(\"Standardization done. Quick shapes:\")\n",
        "for name, df in [(\"movies_items\", movies_items), (\"movies_ratings\", movies_ratings),\n",
        "                 (\"books_items\", books_items), (\"books_ratings\", books_ratings),\n",
        "                 (\"anime_items\", anime_items), (\"anime_ratings\", anime_ratings),\n",
        "                 (\"songs_items\", songs_items), (\"songs_ratings\", songs_ratings)]:\n",
        "    print(f\"{name}: {None if df is None else df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxSQ4zllIAa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6237fd0f-e8e3-4968-b8c1-4edda7949d55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced shapes:\n",
            "movies: (50000, 3) (9742, 3)\n",
            "books: (50000, 3) (271360, 3)\n",
            "anime: (50000, 3) (12294, 3)\n",
            "songs: (50000, 3) (57650, 3)\n"
          ]
        }
      ],
      "source": [
        "# Cell 4 â€” Reduce & sample to memory-safe sizes\n",
        "import numpy as np\n",
        "\n",
        "def reduce_and_sample(df, cols, nrows=None):\n",
        "    if df is None:\n",
        "        return None\n",
        "    # keep only requested cols that exist\n",
        "    present = [c for c in cols if c in df.columns]\n",
        "    small = df[present].copy()\n",
        "    if nrows is not None and len(small) > nrows:\n",
        "        small = small.sample(nrows, random_state=42)\n",
        "    return small\n",
        "\n",
        "# Conservative safe sizes (to avoid RAM crashes)\n",
        "MOVIE_MAX = 50000    # movies ratings\n",
        "BOOK_MAX  = 50000\n",
        "ANIME_MAX = 50000    # make this small to keep memory low\n",
        "SONG_MAX  = 50000\n",
        "\n",
        "movies_ratings_small = reduce_and_sample(movies_ratings, [\"userId\",\"itemId\",\"rating\"], nrows=MOVIE_MAX)\n",
        "movies_items_small   = reduce_and_sample(movies_items, [\"itemId\",\"title\",\"genres\"], nrows=None)\n",
        "\n",
        "books_ratings_small  = reduce_and_sample(books_ratings, [\"userId\",\"itemId\",\"rating\"], nrows=BOOK_MAX)\n",
        "books_items_small    = reduce_and_sample(books_items, [\"itemId\",\"title\",\"genres\"], nrows=None)\n",
        "\n",
        "anime_ratings_small  = reduce_and_sample(anime_ratings, [\"userId\",\"itemId\",\"rating\"], nrows=ANIME_MAX)\n",
        "anime_items_small    = reduce_and_sample(anime_items, [\"itemId\",\"title\",\"genres\"], nrows=None)\n",
        "\n",
        "songs_ratings_small  = reduce_and_sample(songs_ratings, [\"userId\",\"itemId\",\"rating\"], nrows=SONG_MAX)\n",
        "songs_items_small    = reduce_and_sample(songs_items, [\"itemId\",\"title\",\"genres\"], nrows=None)\n",
        "\n",
        "print(\"Reduced shapes:\")\n",
        "print(\"movies:\", movies_ratings_small.shape if movies_ratings_small is not None else None, movies_items_small.shape if movies_items_small is not None else None)\n",
        "print(\"books:\", books_ratings_small.shape if books_ratings_small is not None else None, books_items_small.shape if books_items_small is not None else None)\n",
        "print(\"anime:\", anime_ratings_small.shape if anime_ratings_small is not None else None, anime_items_small.shape if anime_items_small is not None else None)\n",
        "print(\"songs:\", songs_ratings_small.shape if songs_ratings_small is not None else None, songs_items_small.shape if songs_items_small is not None else None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BrD45DCICfo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bce4a55a-ff61-4372-8204-0c1b0629757b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SmartRecommender defined.\n"
          ]
        }
      ],
      "source": [
        "# Cell 5 â€” Memory-safe recommender\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "class SmartRecommender:\n",
        "    \"\"\"\n",
        "    Memory-safe hybrid recommender:\n",
        "      - Content: TF-IDF on genres/title\n",
        "      - Lightweight CF: item co-occurrence via sparse ops (no dense user-user sim matrix)\n",
        "    \"\"\"\n",
        "    def __init__(self, items_df, ratings_df, max_users=5000):\n",
        "        self.items = items_df.reset_index(drop=True).copy() if items_df is not None else pd.DataFrame(columns=[\"itemId\",\"title\",\"genres\"])\n",
        "        self.ratings = ratings_df.copy() if ratings_df is not None else pd.DataFrame(columns=[\"userId\",\"itemId\",\"rating\"])\n",
        "        # ensure types\n",
        "        self.ratings['userId'] = self.ratings['userId'].astype(str)\n",
        "        self.ratings['itemId'] = self.ratings['itemId'].astype(str)\n",
        "        # optionally sample users if too many unique users to save memory\n",
        "        unique_users = self.ratings['userId'].nunique()\n",
        "        if unique_users > max_users:\n",
        "            keep_users = np.random.choice(self.ratings['userId'].unique(), max_users, replace=False)\n",
        "            self.ratings = self.ratings[self.ratings['userId'].isin(keep_users)]\n",
        "        # factorize ids to 0..n-1 for sparse matrices\n",
        "        self.user_map, self.ratings['uidx'] = np.unique(self.ratings['userId'], return_inverse=True)\n",
        "        self.item_map, self.ratings['iidx'] = np.unique(self.ratings['itemId'], return_inverse=True)\n",
        "        # create sparse user-item matrix (u x i)\n",
        "        if len(self.ratings)>0:\n",
        "            self.R = csr_matrix((self.ratings['rating'].astype(float),\n",
        "                                 (self.ratings['uidx'], self.ratings['iidx'])),\n",
        "                                shape=(len(self.user_map), len(self.item_map)))\n",
        "        else:\n",
        "            self.R = csr_matrix((0,0))\n",
        "        # items dataframe: ensure itemId as str to match map\n",
        "        self.items['itemId'] = self.items['itemId'].astype(str)\n",
        "        # prepare TF-IDF on genres (fallback to title if genres empty)\n",
        "        self.items['genres_str'] = self.items['genres'].fillna(\"\").astype(str)\n",
        "        # if genres empty, use title\n",
        "        if self.items['genres_str'].str.strip().eq(\"\").all():\n",
        "            self.items['genres_str'] = self.items['title'].fillna(\"\").astype(str)\n",
        "        self.tfidf = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\", max_features=10000)\n",
        "        try:\n",
        "            self.tfidf_matrix = self.tfidf.fit_transform(self.items['genres_str'].values)\n",
        "        except Exception:\n",
        "            # fallback to zeros if TFIDF fail\n",
        "            self.tfidf_matrix = csr_matrix((len(self.items), 1))\n",
        "        # mapping from itemId -> iidx if present in ratings map, else -1\n",
        "        self.itemid_to_iidx = {iid: idx for idx, iid in enumerate(self.item_map)}\n",
        "        # for items not in item_map, we still want index into items df (we will mask later)\n",
        "        # Pre-normalization flag\n",
        "        self._norm = True\n",
        "\n",
        "    def recommend(self, user_id, top_n=10, model='hybrid', genre_pref=None):\n",
        "        \"\"\"\n",
        "        user_id: can be str/int\n",
        "        model: 'cf', 'content', 'hybrid'\n",
        "        \"\"\"\n",
        "        user_id = str(user_id)\n",
        "        n_items = len(self.items)\n",
        "        scores = np.zeros(n_items, dtype=float)\n",
        "        # CONTENT SCORES\n",
        "        if model in ('content','hybrid'):\n",
        "            # find user's rated items within this recommender (by itemId string)\n",
        "            user_ratings = self.ratings[self.ratings['userId'] == user_id]\n",
        "            if not user_ratings.empty:\n",
        "                # map rated iidx to item dataframe indices via item_map -> items index\n",
        "                rated_iidx = user_ratings['iidx'].values\n",
        "                # create user profile as mean TF-IDF of rated items that exist in items DF\n",
        "                valid = [i for i in rated_iidx if i < self.tfidf_matrix.shape[0]]\n",
        "                if len(valid) > 0:\n",
        "                    user_profile = self.tfidf_matrix[valid].mean(axis=0)\n",
        "                    content_scores = (self.tfidf_matrix @ user_profile.T).A1\n",
        "                    scores += content_scores\n",
        "            # genre_pref boosting\n",
        "            if genre_pref:\n",
        "                for g in genre_pref:\n",
        "                    g = g.strip().lower()\n",
        "                    boost = self.items['genres'].fillna(\"\").astype(str).str.lower().str.contains(g).astype(float).values\n",
        "                    scores += boost * 1.0\n",
        "\n",
        "        # COLLABORATIVE SCORES (lightweight, item co-occurrence)\n",
        "        if model in ('cf','hybrid'):\n",
        "            if user_id in self.user_map:\n",
        "                uidx = int(np.where(self.user_map == user_id)[0])\n",
        "                # user vector (1 x items)\n",
        "                user_vec = self.R.getrow(uidx)  # sparse\n",
        "                if user_vec.nnz > 0:\n",
        "                    # Item similarity via co-occurrence: item_score = user_vec * (R.T * R)\n",
        "                    # But compute efficiently: scores_item = user_vec.dot(R.T).dot(R).toarray().flatten()\n",
        "                    # Use two sparse multiplications (keeps memory low)\n",
        "                    try:\n",
        "                        item_co = user_vec.dot(self.R.T)  # (1 x users)\n",
        "                        item_scores_vec = item_co.dot(self.R)  # (1 x items)\n",
        "                        cf_scores = item_scores_vec.toarray().flatten()\n",
        "                        scores += cf_scores\n",
        "                    except Exception:\n",
        "                        pass\n",
        "\n",
        "        # mask already seen items\n",
        "        seen_items = set(self.ratings.loc[self.ratings['userId'] == user_id, 'itemId'].astype(str).values)\n",
        "        out = []\n",
        "        # compute top indices\n",
        "        idxs = np.argsort(-scores)[:top_n*5]  # take extra and filter seen\n",
        "        for idx in idxs:\n",
        "            if idx < 0 or idx >= n_items:\n",
        "                continue\n",
        "            iid = self.items.iloc[idx]['itemId']\n",
        "            if str(iid) in seen_items:\n",
        "                continue\n",
        "            out.append((iid, self.items.iloc[idx]['title'], self.items.iloc[idx]['genres'], float(scores[idx])))\n",
        "            if len(out) >= top_n:\n",
        "                break\n",
        "        return out\n",
        "\n",
        "    def explain(self, user_id, item_id):\n",
        "        # Minimal explanation: return placeholder scores â€” for a proper explanation you'd compute contributions\n",
        "        return {\"cf_score\": None, \"content_score\": None, \"similar_rated_items\": []}\n",
        "\n",
        "print(\"SmartRecommender defined.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFK2EQ91IFVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d00da28-9fde-43ba-9272-4c5d8881dfa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movies initialized.\n",
            "Books initialized.\n",
            "Anime initialized.\n",
            "Songs initialized.\n",
            "Initialization attempted for all domains. Check above for any skipped/failed domains.\n"
          ]
        }
      ],
      "source": [
        "# Cell 6 â€” Initialize recommender instances one-by-one to avoid spikes\n",
        "RECOMMENDERS = {}\n",
        "\n",
        "def safe_init(name, items_df, ratings_df, max_users=4000):\n",
        "    if items_df is None or ratings_df is None:\n",
        "        print(f\"Skipping {name}: items or ratings missing.\")\n",
        "        return None\n",
        "    try:\n",
        "        rec = SmartRecommender(items_df, ratings_df, max_users=max_users)\n",
        "        print(f\"{name} initialized.\")\n",
        "        return rec\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to init {name}: {e}\")\n",
        "        return None\n",
        "\n",
        "RECOMMENDERS['movies'] = safe_init(\"Movies\", movies_items_small, movies_ratings_small, max_users=3000)\n",
        "RECOMMENDERS['books']  = safe_init(\"Books\", books_items_small, books_ratings_small, max_users=3000)\n",
        "RECOMMENDERS['anime']  = safe_init(\"Anime\", anime_items_small, anime_ratings_small.sample(min(len(anime_ratings_small) if anime_ratings_small is not None else 0, 30000), random_state=42) if anime_ratings_small is not None else None, max_users=3000)\n",
        "RECOMMENDERS['songs']  = safe_init(\"Songs\", songs_items_small, songs_ratings_small.sample(min(len(songs_ratings_small) if songs_ratings_small is not None else 0, 30000), random_state=42) if songs_ratings_small is not None else None, max_users=3000)\n",
        "\n",
        "print(\"Initialization attempted for all domains. Check above for any skipped/failed domains.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvazU6XCIICk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b9b937f-5bd6-41b9-9519-3a90da3d4af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 5 for movies, user 432:\n",
            "[('34540', 'Pretty Persuasion (2005)', 'Comedy|Drama', 0.4014223215119023), ('1292', 'Being There (1979)', 'Comedy|Drama', 0.4014223215119023), ('1300', 'My Life as a Dog (Mitt liv som hund) (1985)', 'Comedy|Drama', 0.4014223215119023), ('1318', 'Blue Juice (1995)', 'Comedy|Drama', 0.4014223215119023), ('59118', 'Happy-Go-Lucky (2008)', 'Comedy|Drama', 0.4014223215119023)]\n",
            "\n",
            "Top 5 for books, user 12110:\n",
            "[('0821745727', 'The Secret Scribbler (Zebra Regency Romance)', 'Cynthia Richey', 1.0), ('1570713383', 'Unstoppable: 45 Powerful Stories of Perseverance and Triumph from People Just Like You', 'Cynthia Kersey', 1.0), ('0671792857', 'TAINTED TRUTH : The Manipulation of Fact in America', 'Cynthia Crossen', 1.0), ('155553046X', 'Machinery of Dominance: Women, Men, and Technical Know-How', 'Cynthia Cockburn', 1.0), ('1567311806', 'The Secret Prophecies of Nostradamus', 'Cynthia Sternau', 1.0)]\n",
            "\n",
            "Top 5 for anime, user 777:\n",
            "[('3603', 'JoJo no Kimyou na Bouken: Phantom Blood', 'Action, Adventure, Horror, Shounen, Vampire', 0.9999999999999999), ('2130', 'Kaibutsu Oujo', 'Action, Comedy, Horror, Shounen, Supernatural, Vampire', 0.8573999913962711), ('6920', 'Blade', 'Action, Drama, Horror, Vampire', 0.8367279161478811), ('666', 'JoJo no Kimyou na Bouken', 'Adventure, Drama, Fantasy, Horror, Shounen, Supernatural, Vampire', 0.8132822552798922), ('665', 'JoJo no Kimyou na Bouken: Adventure', 'Adventure, Drama, Fantasy, Horror, Shounen, Supernatural, Vampire', 0.8132822552798922)]\n",
            "\n",
            "Top 5 for songs, user default_user:\n",
            "[('25813', 'Eternal Circle', 'Bob Dylan', 0.01028159977350471), ('25815', 'Every Grain Of Sand', 'Bob Dylan', 0.01028159977350471), ('25818', 'Farewell Angelina', 'Bob Dylan', 0.01028159977350471), ('25822', 'Forever Young', 'Bob Dylan', 0.01028159977350471), ('25827', 'Gates Of Eden', 'Bob Dylan', 0.01028159977350471)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2649856874.py:85: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  uidx = int(np.where(self.user_map == user_id)[0])\n",
            "/tmp/ipython-input-2649856874.py:85: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  uidx = int(np.where(self.user_map == user_id)[0])\n",
            "/tmp/ipython-input-2649856874.py:85: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  uidx = int(np.where(self.user_map == user_id)[0])\n",
            "/tmp/ipython-input-2649856874.py:85: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  uidx = int(np.where(self.user_map == user_id)[0])\n"
          ]
        }
      ],
      "source": [
        "# Cell 7 â€” Quick local tests (use IDs that exist in your small datasets)\n",
        "for domain in ['movies','books','anime','songs']:\n",
        "    rec = RECOMMENDERS.get(domain)\n",
        "    if rec is None:\n",
        "        print(domain, \"not initialized\")\n",
        "        continue\n",
        "    # pick a test user (first user in ratings if present)\n",
        "    if len(rec.ratings) > 0:\n",
        "        test_user = rec.ratings['userId'].iloc[0]\n",
        "        print(f\"\\nTop 5 for {domain}, user {test_user}:\")\n",
        "        print(rec.recommend(test_user, top_n=5))\n",
        "    else:\n",
        "        print(domain, \"has no ratings in sampled set.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e49b1c7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "af7b6e99-8e37-4afd-ade9-15380d6d5195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio_client/documentation.py:106: UserWarning: Could not get documentation group for <class 'gradio.mix.Parallel'>: No known documentation group for module 'gradio.mix'\n",
            "  warnings.warn(f\"Could not get documentation group for {cls}: {exc}\")\n",
            "/usr/local/lib/python3.12/dist-packages/gradio_client/documentation.py:106: UserWarning: Could not get documentation group for <class 'gradio.mix.Series'>: No known documentation group for module 'gradio.mix'\n",
            "  warnings.warn(f\"Could not get documentation group for {cls}: {exc}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        " # Cell 8 â€” Gradio interface (with fixed genre dropdown)\n",
        "import gradio as gr\n",
        "\n",
        "# Fixed genre options (you can expand this list as needed)\n",
        "GENRE_OPTIONS = [\n",
        "    \"Action\", \"Adventure\", \"Animation\", \"Comedy\", \"Crime\",\n",
        "    \"Documentary\", \"Drama\", \"Family\", \"Fantasy\", \"History\",\n",
        "    \"Horror\", \"Music\", \"Mystery\", \"Romance\", \"Science Fiction\",\n",
        "    \"Thriller\", \"War\", \"Western\"\n",
        "]\n",
        "\n",
        "def gradio_recommend(domain, user_id, top_n, model_choice, genre_pref):\n",
        "    if domain not in RECOMMENDERS or RECOMMENDERS[domain] is None:\n",
        "        return f\"Recommender for {domain} not initialized.\"\n",
        "    # genre_pref is already a list of selected values\n",
        "    recs = RECOMMENDERS[domain].recommend(user_id, top_n=int(top_n), model=model_choice, genre_pref=genre_pref)\n",
        "    if not recs:\n",
        "        return \"No recommendations â€” try a different user id or domain.\"\n",
        "    # nicely format\n",
        "    lines = []\n",
        "    for i, (iid, title, genres, score) in enumerate(recs, 1):\n",
        "        lines.append(f\"{i}. {title}  â€”  {genres}  â€”  score: {score:.3f}\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "domain_input = gr.Dropdown(\n",
        "    choices=[k for k in RECOMMENDERS.keys() if RECOMMENDERS[k] is not None],\n",
        "    label=\"Domain\", value=\"movies\"\n",
        ")\n",
        "user_input = gr.Textbox(label=\"User ID\", value=\"1\", placeholder=\"Enter a user id from dataset (as string or number)\")\n",
        "top_n = gr.Slider(1, 20, value=5, step=1, label=\"Top N\")\n",
        "model_choice = gr.Dropdown([\"hybrid\",\"cf\",\"content\"], value=\"hybrid\", label=\"Model\")\n",
        "\n",
        "# Genre selection dropdown (multi-select allowed)\n",
        "genre_pref = gr.Dropdown(\n",
        "    choices=GENRE_OPTIONS,\n",
        "    multiselect=True,\n",
        "    label=\"Preferred Genres\"\n",
        ")\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=gradio_recommend,\n",
        "    inputs=[domain_input, user_input, top_n, model_choice, genre_pref],\n",
        "    outputs=gr.Textbox(label=\"Recommendations\"),\n",
        "    title=\"Multi-Domain Smart Recommender\",\n",
        "    description=\"Choose domain and user to get recommendations (memory-safe).\"\n",
        ")\n",
        "\n",
        "demo.launch(share=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1ZxKFObigoT6MOzTY34gl"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}